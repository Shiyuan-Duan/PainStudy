{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from utils import get_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "SEP = '*'*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result on test: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.89      0.83      4153\n",
      "         1.0       0.18      0.09      0.12      1200\n",
      "\n",
      "    accuracy                           0.71      5353\n",
      "   macro avg       0.48      0.49      0.47      5353\n",
      "weighted avg       0.64      0.71      0.67      5353\n",
      "\n",
      "[[3688  465]\n",
      " [1097  103]]\n",
      "**********\n",
      "result on test: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.74      0.84      9561\n",
      "         1.0       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.73      9691\n",
      "   macro avg       0.49      0.37      0.42      9691\n",
      "weighted avg       0.97      0.73      0.83      9691\n",
      "\n",
      "[[7068 2493]\n",
      " [ 130    0]]\n",
      "**********\n",
      "result on test: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.86      0.80      6167\n",
      "         1.0       0.03      0.01      0.02      1800\n",
      "\n",
      "    accuracy                           0.66      7967\n",
      "   macro avg       0.39      0.43      0.41      7967\n",
      "weighted avg       0.59      0.66      0.62      7967\n",
      "\n",
      "[[5273  894]\n",
      " [1775   25]]\n",
      "**********\n",
      "result on test: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85     10187\n",
      "         1.0       0.22      0.45      0.29      1350\n",
      "\n",
      "    accuracy                           0.75     11537\n",
      "   macro avg       0.57      0.62      0.57     11537\n",
      "weighted avg       0.83      0.75      0.78     11537\n",
      "\n",
      "[[8011 2176]\n",
      " [ 744  606]]\n",
      "**********\n",
      "result on test: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.91      0.82      5029\n",
      "         1.0       0.10      0.03      0.05      1650\n",
      "\n",
      "    accuracy                           0.70      6679\n",
      "   macro avg       0.42      0.47      0.43      6679\n",
      "weighted avg       0.58      0.70      0.63      6679\n",
      "\n",
      "[[4595  434]\n",
      " [1602   48]]\n",
      "**********\n",
      "result on test: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.80      7630\n",
      "         1.0       0.03      0.02      0.02      2100\n",
      "\n",
      "    accuracy                           0.67      9730\n",
      "   macro avg       0.40      0.44      0.41      9730\n",
      "weighted avg       0.60      0.67      0.64      9730\n",
      "\n",
      "[[6514 1116]\n",
      " [2061   39]]\n",
      "**********\n",
      "result on test: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85      9021\n",
      "         1.0       0.01      0.08      0.02       300\n",
      "\n",
      "    accuracy                           0.74      9321\n",
      "   macro avg       0.49      0.42      0.44      9321\n",
      "weighted avg       0.93      0.74      0.83      9321\n",
      "\n",
      "[[6913 2108]\n",
      " [ 275   25]]\n",
      "**********\n",
      "result on test: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.80      0.82     10058\n",
      "         1.0       0.13      0.16      0.14      1800\n",
      "\n",
      "    accuracy                           0.71     11858\n",
      "   macro avg       0.49      0.48      0.48     11858\n",
      "weighted avg       0.73      0.71      0.72     11858\n",
      "\n",
      "[[8082 1976]\n",
      " [1505  295]]\n",
      "**********\n",
      "result on test: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.86      0.91     46499\n",
      "         1.0       0.04      0.17      0.06      1393\n",
      "\n",
      "    accuracy                           0.84     47892\n",
      "   macro avg       0.50      0.52      0.49     47892\n",
      "weighted avg       0.94      0.84      0.89     47892\n",
      "\n",
      "[[40096  6403]\n",
      " [ 1159   234]]\n",
      "**********\n",
      "result on test: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95     32824\n",
      "         1.0       0.00      0.01      0.00      1200\n",
      "\n",
      "    accuracy                           0.90     34024\n",
      "   macro avg       0.48      0.47      0.48     34024\n",
      "weighted avg       0.93      0.90      0.91     34024\n",
      "\n",
      "[[30555  2269]\n",
      " [ 1193     7]]\n",
      "**********\n",
      "result on test: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.86      0.92     27457\n",
      "         1.0       0.18      0.62      0.27      1300\n",
      "\n",
      "    accuracy                           0.85     28757\n",
      "   macro avg       0.58      0.74      0.60     28757\n",
      "weighted avg       0.94      0.85      0.89     28757\n",
      "\n",
      "[[23727  3730]\n",
      " [  499   801]]\n",
      "**********\n",
      "result on test: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.87     25104\n",
      "         1.0       0.06      0.07      0.06      3300\n",
      "\n",
      "    accuracy                           0.77     28404\n",
      "   macro avg       0.47      0.46      0.46     28404\n",
      "weighted avg       0.78      0.77      0.77     28404\n",
      "\n",
      "[[21535  3569]\n",
      " [ 3085   215]]\n",
      "**********\n",
      "result on test: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94     28263\n",
      "         1.0       0.00      0.00      0.00      1400\n",
      "\n",
      "    accuracy                           0.89     29663\n",
      "   macro avg       0.47      0.47      0.47     29663\n",
      "weighted avg       0.90      0.89      0.90     29663\n",
      "\n",
      "[[26297  1966]\n",
      " [ 1400     0]]\n",
      "**********\n",
      "result on test: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.80      0.78     27842\n",
      "         1.0       0.14      0.11      0.13      7800\n",
      "\n",
      "    accuracy                           0.65     35642\n",
      "   macro avg       0.45      0.46      0.45     35642\n",
      "weighted avg       0.63      0.65      0.64     35642\n",
      "\n",
      "[[22317  5525]\n",
      " [ 6909   891]]\n",
      "**********\n",
      "result on test: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.85      0.89     28241\n",
      "         1.0       0.08      0.19      0.12      2100\n",
      "\n",
      "    accuracy                           0.80     30341\n",
      "   macro avg       0.51      0.52      0.50     30341\n",
      "weighted avg       0.87      0.80      0.84     30341\n",
      "\n",
      "[[23987  4254]\n",
      " [ 1706   394]]\n",
      "**********\n",
      "result on test: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     26612\n",
      "         1.0       0.46      0.38      0.41      2100\n",
      "\n",
      "    accuracy                           0.92     28712\n",
      "   macro avg       0.70      0.67      0.69     28712\n",
      "weighted avg       0.92      0.92      0.92     28712\n",
      "\n",
      "[[25675   937]\n",
      " [ 1311   789]]\n",
      "**********\n",
      "result on test: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97     28562\n",
      "         1.0       0.00      0.00      0.00      1176\n",
      "\n",
      "    accuracy                           0.95     29738\n",
      "   macro avg       0.48      0.49      0.49     29738\n",
      "weighted avg       0.92      0.95      0.94     29738\n",
      "\n",
      "[[28272   290]\n",
      " [ 1176     0]]\n",
      "**********\n",
      "result on test: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.86      0.91     26974\n",
      "         1.0       0.08      0.35      0.14      1000\n",
      "\n",
      "    accuracy                           0.84     27974\n",
      "   macro avg       0.53      0.60      0.52     27974\n",
      "weighted avg       0.94      0.84      0.89     27974\n",
      "\n",
      "[[23199  3775]\n",
      " [  651   349]]\n",
      "**********\n",
      "result on test: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     34276\n",
      "         1.0       0.00      0.00      0.00      1550\n",
      "\n",
      "    accuracy                           0.92     35826\n",
      "   macro avg       0.48      0.48      0.48     35826\n",
      "weighted avg       0.91      0.92      0.92     35826\n",
      "\n",
      "[[33037  1239]\n",
      " [ 1550     0]]\n",
      "**********\n",
      "result on test: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     24667\n",
      "         1.0       0.17      0.17      0.17      1530\n",
      "\n",
      "    accuracy                           0.90     26197\n",
      "   macro avg       0.56      0.56      0.56     26197\n",
      "weighted avg       0.90      0.90      0.90     26197\n",
      "\n",
      "[[23382  1285]\n",
      " [ 1275   255]]\n",
      "**********\n",
      "result on test: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94     29335\n",
      "         1.0       0.02      0.41      0.04       180\n",
      "\n",
      "    accuracy                           0.89     29515\n",
      "   macro avg       0.51      0.65      0.49     29515\n",
      "weighted avg       0.99      0.89      0.93     29515\n",
      "\n",
      "[[26124  3211]\n",
      " [  106    74]]\n",
      "**********\n",
      "result on test: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84     24064\n",
      "         1.0       0.02      0.04      0.03      2400\n",
      "\n",
      "    accuracy                           0.73     26464\n",
      "   macro avg       0.46      0.42      0.43     26464\n",
      "weighted avg       0.81      0.73      0.77     26464\n",
      "\n",
      "[[19112  4952]\n",
      " [ 2297   103]]\n",
      "**********\n",
      "result on test: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.84     20671\n",
      "         1.0       0.03      0.24      0.06       700\n",
      "\n",
      "    accuracy                           0.73     21371\n",
      "   macro avg       0.50      0.49      0.45     21371\n",
      "weighted avg       0.94      0.73      0.82     21371\n",
      "\n",
      "[[15503  5168]\n",
      " [  532   168]]\n",
      "**********\n",
      "result on test: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.84      0.90     25670\n",
      "         1.0       0.07      0.28      0.11      1070\n",
      "\n",
      "    accuracy                           0.81     26740\n",
      "   macro avg       0.52      0.56      0.50     26740\n",
      "weighted avg       0.93      0.81      0.86     26740\n",
      "\n",
      "[[21471  4199]\n",
      " [  769   301]]\n",
      "**********\n",
      "result on test: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.92     25240\n",
      "         1.0       0.13      0.36      0.19      1310\n",
      "\n",
      "    accuracy                           0.85     26550\n",
      "   macro avg       0.55      0.62      0.55     26550\n",
      "weighted avg       0.92      0.85      0.88     26550\n",
      "\n",
      "[[22067  3173]\n",
      " [  833   477]]\n",
      "**********\n",
      "result on test: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93     27056\n",
      "         1.0       0.09      0.11      0.10      1920\n",
      "\n",
      "    accuracy                           0.87     28976\n",
      "   macro avg       0.51      0.51      0.51     28976\n",
      "weighted avg       0.88      0.87      0.87     28976\n",
      "\n",
      "[[24946  2110]\n",
      " [ 1715   205]]\n",
      "**********\n",
      "result on test: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.77      0.84     25469\n",
      "         1.0       0.04      0.13      0.06      1900\n",
      "\n",
      "    accuracy                           0.73     27369\n",
      "   macro avg       0.48      0.45      0.45     27369\n",
      "weighted avg       0.86      0.73      0.79     27369\n",
      "\n",
      "[[19656  5813]\n",
      " [ 1658   242]]\n",
      "**********\n",
      "result on test: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94     25300\n",
      "         1.0       0.14      0.24      0.17      1230\n",
      "\n",
      "    accuracy                           0.89     26530\n",
      "   macro avg       0.55      0.58      0.56     26530\n",
      "weighted avg       0.92      0.89      0.91     26530\n",
      "\n",
      "[[23376  1924]\n",
      " [  929   301]]\n",
      "**********\n",
      "result on test: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     25192\n",
      "         1.0       0.09      0.13      0.11      1070\n",
      "\n",
      "    accuracy                           0.91     26262\n",
      "   macro avg       0.53      0.54      0.53     26262\n",
      "weighted avg       0.93      0.91      0.92     26262\n",
      "\n",
      "[[23829  1363]\n",
      " [  928   142]]\n",
      "**********\n",
      "result on test: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     24296\n",
      "         1.0       0.16      0.03      0.05      3340\n",
      "\n",
      "    accuracy                           0.86     27636\n",
      "   macro avg       0.52      0.50      0.49     27636\n",
      "weighted avg       0.79      0.86      0.82     27636\n",
      "\n",
      "[[23792   504]\n",
      " [ 3247    93]]\n",
      "**********\n",
      "result on test: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90     26991\n",
      "         1.0       0.01      0.04      0.02      1370\n",
      "\n",
      "    accuracy                           0.82     28361\n",
      "   macro avg       0.48      0.45      0.46     28361\n",
      "weighted avg       0.90      0.82      0.86     28361\n",
      "\n",
      "[[23112  3879]\n",
      " [ 1317    53]]\n",
      "**********\n",
      "result on test: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     25993\n",
      "         1.0       0.15      0.14      0.14      1580\n",
      "\n",
      "    accuracy                           0.91     27573\n",
      "   macro avg       0.55      0.54      0.55     27573\n",
      "weighted avg       0.90      0.91      0.90     27573\n",
      "\n",
      "[[24756  1237]\n",
      " [ 1366   214]]\n",
      "**********\n",
      "result on test: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94     26382\n",
      "         1.0       0.39      0.35      0.37      2830\n",
      "\n",
      "    accuracy                           0.88     29212\n",
      "   macro avg       0.66      0.65      0.65     29212\n",
      "weighted avg       0.88      0.88      0.88     29212\n",
      "\n",
      "[[24801  1581]\n",
      " [ 1832   998]]\n",
      "**********\n",
      "result on test: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88     22569\n",
      "         1.0       0.20      0.11      0.14      4090\n",
      "\n",
      "    accuracy                           0.79     26659\n",
      "   macro avg       0.53      0.52      0.51     26659\n",
      "weighted avg       0.75      0.79      0.77     26659\n",
      "\n",
      "[[20717  1852]\n",
      " [ 3627   463]]\n",
      "**********\n",
      "result on test: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94     28649\n",
      "         1.0       0.31      0.25      0.28      2600\n",
      "\n",
      "    accuracy                           0.89     31249\n",
      "   macro avg       0.62      0.60      0.61     31249\n",
      "weighted avg       0.88      0.89      0.89     31249\n",
      "\n",
      "[[27178  1471]\n",
      " [ 1939   661]]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(1, 37):\n",
    "    if t == 11: continue\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    test_subjects = [t]\n",
    "    for i in range(1, 37):\n",
    "        if i == 11: continue\n",
    "        if i in test_subjects:\n",
    "            X_test.append(get_data(i))\n",
    "        else:\n",
    "            X_train.append(get_data(i))\n",
    "\n",
    "    X_train = np.vstack(X_train)\n",
    "    y_train = X_train[:, -1]\n",
    "    X_train = X_train[:, :-1]\n",
    "\n",
    "    X_test = np.vstack(X_test)\n",
    "    y_test = X_test[:, -1]\n",
    "    X_test = X_test[:, :-1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)\n",
    "    clf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight, objective='binary:logistic')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f'result on test: {t}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(SEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94     28649\n",
      "         1.0       0.31      0.25      0.28      2600\n",
      "\n",
      "    accuracy                           0.89     31249\n",
      "   macro avg       0.62      0.60      0.61     31249\n",
      "weighted avg       0.88      0.89      0.89     31249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27178,  1471],\n",
       "       [ 1939,   661]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
